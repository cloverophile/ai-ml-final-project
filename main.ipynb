{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee299dd",
   "metadata": {},
   "source": [
    "Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4edd5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def create_dataloaders(train_dir, val_dir, test_dir, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create DataLoaders for train, validation, and test datasets.\n",
    "\n",
    "    Args:\n",
    "        train_dir (str): Path to the training directory with augmented images.\n",
    "        val_dir (str): Path to the validation directory.\n",
    "        test_dir (str): Path to the test directory.\n",
    "        batch_size (int): Batch size for DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader, class_names\n",
    "    \"\"\"\n",
    "    #transforms\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),   \n",
    "        transforms.ToTensor(),          \n",
    "        transforms.Normalize([0.5], [0.5])  # normalize images to mean=0.5, std=0.5\n",
    "    ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  \n",
    "        transforms.ToTensor(),          \n",
    "        transforms.Normalize([0.5], [0.5])  \n",
    "    ])\n",
    "\n",
    "    # load datasets\n",
    "    train_dataset = ImageFolder(root=train_dir, transform=train_transforms)\n",
    "    val_dataset = ImageFolder(root=val_dir, transform=test_transforms)\n",
    "    test_dataset = ImageFolder(root=test_dir, transform=test_transforms)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047b969",
   "metadata": {},
   "source": [
    "Training / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffbc7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "# Configuration\n",
    "save_model_path = \"checkpoints/\"\n",
    "pth_name = \"saved_model.pth\"\n",
    "os.makedirs(save_model_path, exist_ok=True)\n",
    "\n",
    "def val(model, val_loader, loss_function, writer, epoch, device):\n",
    "    f1 = F1Score(num_classes=len(val_loader.dataset.classes),average='weighted', task='multiclass')\n",
    "    val_iterator = enumerate(val_loader)\n",
    "    f1_list, f1t_list = [], []\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    tq = tqdm.tqdm(total=len(val_loader), desc=\"Validation\")\n",
    "    with torch.no_grad():\n",
    "        for _, (images, labels) in val_iterator:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(images)\n",
    "            loss = loss_function(predictions, labels.long())  # Change labels to .long()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute predictions\n",
    "            #predictions = predictions.softmax(dim=1)\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            f1_list.extend(predictions.cpu().numpy())\n",
    "            f1t_list.extend(labels.cpu().numpy())\n",
    "            # Calculate accuracy\n",
    "            #_, predicted = torch.max(predictions, 1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "\n",
    "            tq.update(1)\n",
    "\n",
    "    tq.close()\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1_score_value = f1(torch.tensor(f1_list), torch.tensor(f1t_list))\n",
    "    val_accuracy = total_correct / total_samples\n",
    "\n",
    "    writer.add_scalar(\"Validation F1\", f1_score_value, epoch)\n",
    "    writer.add_scalar(\"Validation Loss\", total_loss / len(val_loader), epoch)\n",
    "    writer.add_scalar(\"Validation Accuracy\", val_accuracy, epoch)\n",
    "\n",
    "    #print(f'list_pred {f1_list}')\n",
    "    #print(f'list_pred {f1t_list}')\n",
    "    print(f\"Validation Loss: {total_loss / len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {f1_score_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, loss_fn, n_epochs, device):\n",
    "    \"\"\"\n",
    "    Train the model on the training dataset.\n",
    "    Logs loss and saves the model at each epoch.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model.\n",
    "        train_loader: DataLoader for training data.\n",
    "        val_loader: DataLoader for validation data.\n",
    "        optimizer: Optimizer for training.\n",
    "        loss_fn: Loss function.\n",
    "        n_epochs: Number of epochs.\n",
    "        device: Device for computation (CPU/GPU).\n",
    "    \"\"\"\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()  \n",
    "        running_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        f1 = F1Score(num_classes=len(train_loader.dataset.classes),average='weighted', task='multiclass').to(device)  # Move F1 metric to device\n",
    "\n",
    "        tq = tqdm.tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Compute predictions\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Update F1 score\n",
    "            f1.update(predictions, labels)\n",
    "            \n",
    "            # Accuracy calculation\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            tq.set_postfix(loss=loss.item())\n",
    "            tq.update(1)\n",
    "\n",
    "        tq.close()\n",
    "\n",
    "        # Compute F1 score at the end of the epoch\n",
    "        f1_score_value = f1.compute()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        train_accuracy = total_correct / total_samples\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Log training metrics\n",
    "        writer.add_scalar(\"Training Loss\", epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Training Accuracy\", train_accuracy, epoch)\n",
    "        writer.add_scalar(\"Training F1\", f1_score_value, epoch)\n",
    "\n",
    "        # Print training metrics\n",
    "        print(f\"Epoch [{epoch + 1}/{n_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Training F1: {f1_score_value:.4f}\")\n",
    "\n",
    "        # Validate the model\n",
    "        val(model, val_loader, loss_fn, writer, epoch, device)\n",
    "\n",
    "        # Save the model checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(save_model_path, pth_name))\n",
    "        print(f\"Model saved at {save_model_path}{pth_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66a2e0f",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9ff3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import tqdm  # Correct import for tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "def test(model, test_data_path, device, batch_size=32, image_size=(128, 128), mean=[0.5], std=[0.5]):\n",
    "    \"\"\"\n",
    "    Evaluates a trained model on a test dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The model to evaluate.\n",
    "    - test_data_path (str): Path to the test dataset.\n",
    "    - device (torch.device): The device to run the evaluation on (CPU or CUDA).\n",
    "    - batch_size (int, optional): The batch size for the DataLoader. Default is 32.\n",
    "    - image_size (tuple, optional): The target image size for the input images. Default is (128, 128).\n",
    "    - mean (list, optional): The mean for normalization. Default is [0.5].\n",
    "    - std (list, optional): The std for normalization. Default is [0.5].\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints the accuracy and F1 score of the model on the test set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load test dataset with transformations\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(image_size),  # Resize to match input size for the model\n",
    "        transforms.ToTensor(),          # Convert PIL images to tensors\n",
    "        transforms.Normalize(mean=mean, std=std)  # Normalize (same mean/std as training)\n",
    "    ])\n",
    "\n",
    "    test_dataset = ImageFolder(root=test_data_path, transform=test_transforms)\n",
    "    class_names = test_dataset.classes  # Retrieve class names\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables to store true labels and predicted labels\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        for inputs, labels in tqdm.tqdm(test_loader, desc=\"Evaluating\"):  # Use tqdm from the module\n",
    "            # Move the inputs and labels to the device (GPU or CPU)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)  # Get the predicted class (index of max logit)\n",
    "\n",
    "            # Append true and predicted labels to the lists\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Compute accuracy and F1 score\n",
    "    accuracy = accuracy_score(all_true_labels, all_pred_labels)\n",
    "    f1 = f1_score(all_true_labels, all_pred_labels, average='macro')  # Weighted F1 score\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score (Macro): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed076bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/validation' \n",
    "test_dir = 'dataset/test'         \n",
    "log_dir = \"outputs/logs\"        \n",
    "model_dir = \"outputs/models\"    # Model save path\n",
    "batch_size = 32\n",
    "num_epochs = 2\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2aa2c7",
   "metadata": {},
   "source": [
    "initializing dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5777e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, class_names = create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    val_dir=val_dir,\n",
    "    test_dir=test_dir,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c175574c",
   "metadata": {},
   "source": [
    "<h1>Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a6a64b",
   "metadata": {},
   "source": [
    "<h2>Resnet18 pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c71d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "def get_resnet18_pretrained(num_classes, transfer_learning=True):\n",
    "    model = models.resnet18(pretrained=transfer_learning)\n",
    "    if transfer_learning:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379665e",
   "metadata": {},
   "source": [
    "with sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99731cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/2: 100%|██████████| 90/90 [00:10<00:00,  8.30it/s, loss=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.6355, Training Accuracy: 0.6697, Training F1: 0.6697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5304, Validation Accuracy: 0.7444, Validation F1 Score: 0.7398\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 90/90 [00:06<00:00, 13.41it/s, loss=0.186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.4865, Training Accuracy: 0.7629, Training F1: 0.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5018, Validation Accuracy: 0.7611, Validation F1 Score: 0.7564\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "ResNet18 model saved to outputs/models\\resnet18_pretrained_sgd.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7321\n",
      "F1 Score (Macro): 0.7304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ResNet18 Training\n",
    "print(\"Training ResNet18...\")\n",
    "\n",
    "# Initialize the ResNet18 model with the number of classes\n",
    "resnet18_pretrained_sgd = get_resnet18_pretrained(num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_sgd = torch.optim.SGD(resnet18_pretrained_sgd.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=resnet18_pretrained_sgd,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_sgd,\n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(resnet18_pretrained_sgd.state_dict(), os.path.join(model_dir, \"resnet18_pretrained_sgd.pth\"))\n",
    "print(f\"ResNet18 model saved to {os.path.join(model_dir, 'resnet18_pretrained_sgd.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(resnet18_pretrained_sgd, test_data_path=test_dir, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f2984",
   "metadata": {},
   "source": [
    "with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37022c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/2: 100%|██████████| 90/90 [00:10<00:00,  9.00it/s, loss=0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.7232, Training Accuracy: 0.5548, Training F1: 0.5545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6957, Validation Accuracy: 0.6444, Validation F1 Score: 0.6369\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 90/90 [00:07<00:00, 12.21it/s, loss=0.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.6502, Training Accuracy: 0.6278, Training F1: 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6645, Validation Accuracy: 0.6722, Validation F1 Score: 0.6524\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "ResNet18 model saved to outputs/models\\resnet18_pretrained_adam.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6071\n",
      "F1 Score (Macro): 0.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resnet18_pretrained_adam = get_resnet18_pretrained(num_classes=len(class_names)).to(device)\n",
    "optimizer_adam = torch.optim.Adam(resnet18_pretrained_adam.parameters(), lr=0.0001)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=resnet18_pretrained_adam,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_adam,\n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(resnet18_pretrained_adam.state_dict(), os.path.join(model_dir, \"resnet18_pretrained_adam.pth\"))\n",
    "print(f\"ResNet18 model saved to {os.path.join(model_dir, 'resnet18_pretrained_adam.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(resnet18_pretrained_adam, test_data_path=test_dir, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b2988",
   "metadata": {},
   "source": [
    "<h2>Resnet18 not-pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2419daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet18_np(num_classes, transfer_learning=False):\n",
    "    model = models.resnet18(pretrained=False)  # Do not load pre-trained weights\n",
    "    '''if transfer_learning:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False  # Freeze all layers if transfer learning '''\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace4ccb9",
   "metadata": {},
   "source": [
    "with sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03a7f74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/2: 100%|██████████| 90/90 [00:09<00:00,  9.01it/s, loss=0.343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.5869, Training Accuracy: 0.6858, Training F1: 0.6858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5309, Validation Accuracy: 0.7889, Validation F1 Score: 0.7868\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 90/90 [00:08<00:00, 10.95it/s, loss=0.53] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.5004, Training Accuracy: 0.7542, Training F1: 0.7541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5192, Validation Accuracy: 0.7722, Validation F1 Score: 0.7719\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "ResNet18 model saved to outputs/models\\resnet18_sgd.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7143\n",
      "F1 Score (Macro): 0.7110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ResNet18 Training\n",
    "print(\"Training ResNet18...\")\n",
    "\n",
    "# Initialize the ResNet18 model with the number of classes\n",
    "resnet18_sgd = get_resnet18_np(num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_sgd = torch.optim.SGD(resnet18_sgd.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=resnet18_sgd,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_sgd,\n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(resnet18_sgd.state_dict(), os.path.join(model_dir, \"resnet18_sgd.pth\"))\n",
    "print(f\"ResNet18 model saved to {os.path.join(model_dir, 'resnet18_sgd.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(resnet18_sgd, test_data_path=test_dir, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597af03",
   "metadata": {},
   "source": [
    "with adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d0b098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/2: 100%|██████████| 90/90 [00:10<00:00,  8.96it/s, loss=0.0642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.3491, Training Accuracy: 0.8425, Training F1: 0.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6430, Validation Accuracy: 0.7500, Validation F1 Score: 0.7494\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 90/90 [00:08<00:00, 11.10it/s, loss=0.132]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.0616, Training Accuracy: 0.9797, Training F1: 0.9797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8122, Validation Accuracy: 0.7444, Validation F1 Score: 0.7419\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "ResNet18 model saved to outputs/models\\resnet18_adam.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:00<00:00, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7366\n",
      "F1 Score (Macro): 0.7357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resnet18_adam = get_resnet18_np(num_classes=len(class_names)).to(device)\n",
    "optimizer_adam = torch.optim.Adam(resnet18_adam.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=resnet18_adam,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_adam,\n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(resnet18_adam.state_dict(), os.path.join(model_dir, \"resnet18_adam.pth\"))\n",
    "print(f\"ResNet18 model saved to {os.path.join(model_dir, 'resnet18_adam.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(resnet18_adam, test_data_path=test_dir, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095a037",
   "metadata": {},
   "source": [
    "<h1>VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83e1d7",
   "metadata": {},
   "source": [
    "<h2> Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9de6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg16_pretrained(num_classes, transfer_learning=True):\n",
    "    model = models.vgg16(pretrained=transfer_learning)\n",
    "    if transfer_learning:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0bc08",
   "metadata": {},
   "source": [
    "with sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13a5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/2: 100%|██████████| 90/90 [00:26<00:00,  3.41it/s, loss=0.684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.6878, Training Accuracy: 0.5590, Training F1: 0.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6738, Validation Accuracy: 0.6556, Validation F1 Score: 0.6156\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 90/90 [00:26<00:00,  3.37it/s, loss=0.496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.6256, Training Accuracy: 0.7022, Training F1: 0.6936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5634, Validation Accuracy: 0.7333, Validation F1 Score: 0.7333\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "VGG16 model saved to outputs/models\\vgg16_pretrained_sgd.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6964\n",
      "F1 Score (Macro): 0.6958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# VGG16 Training\n",
    "print(\"Training VGG16...\")\n",
    "\n",
    "vgg16_pretrained_sgd = get_vgg16_pretrained(num_classes=len(class_names)).to(device)\n",
    "\n",
    "optimizer_sgd = torch.optim.SGD(vgg16_pretrained_sgd.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=vgg16_pretrained_sgd,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_sgd,\n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(vgg16_pretrained_sgd.state_dict(), os.path.join(model_dir, \"vgg16_pretrained_sgd.pth\"))\n",
    "print(f\"VGG16 model saved to {os.path.join(model_dir, 'vgg16_pretrained_sgd.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(vgg16_pretrained_sgd, test_data_path=test_dir, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586ad26",
   "metadata": {},
   "source": [
    "with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df54a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/3: 100%|██████████| 90/90 [00:15<00:00,  5.83it/s, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Training Loss: 0.6083, Training Accuracy: 0.6676, Training F1: 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4521, Validation Accuracy: 0.8000, Validation F1 Score: 0.7964\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 90/90 [00:15<00:00,  5.93it/s, loss=0.458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Training Loss: 0.4349, Training Accuracy: 0.8066, Training F1: 0.8066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3535, Validation Accuracy: 0.8667, Validation F1 Score: 0.8656\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 90/90 [00:15<00:00,  5.78it/s, loss=0.381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Training Loss: 0.3252, Training Accuracy: 0.8680, Training F1: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3026, Validation Accuracy: 0.8778, Validation F1 Score: 0.8774\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "VGG16 model saved to outputs/models\\vgg16_pretrained_adam.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8348\n",
      "F1 Score (Macro): 0.8348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training VGG16...\")\n",
    "\n",
    "vgg16_pretrained_adam = get_vgg16_pretrained(num_classes=len(class_names)).to(device)\n",
    "\n",
    "optimizer_adam = torch.optim.Adam(vgg16_pretrained_adam.parameters(), lr=0.00001)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=vgg16_pretrained_adam,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_adam,\n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(vgg16_pretrained_adam.state_dict(), os.path.join(model_dir, \"vgg16_pretrained_adam.pth\"))\n",
    "print(f\"VGG16 model saved to {os.path.join(model_dir, 'vgg16_pretrained_adam.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(vgg16_pretrained_adam, test_data_path=test_dir, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75082a35",
   "metadata": {},
   "source": [
    "<h2>Not-pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d862b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg16_np(num_classes, transfer_learning=False):\n",
    "    model = models.vgg16(pretrained=False)  # Do not load pre-trained weights\n",
    "    ''''if transfer_learning:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False  # Freeze all layers of 'features' if transfer learning'''\n",
    "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c33fa5",
   "metadata": {},
   "source": [
    "with sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff1134ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16 (without pretrained weights)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/2: 100%|██████████| 90/90 [00:26<00:00,  3.44it/s, loss=0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.6837, Training Accuracy: 0.5817, Training F1: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6662, Validation Accuracy: 0.6222, Validation F1 Score: 0.6065\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 90/90 [00:26<00:00,  3.45it/s, loss=0.463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.5955, Training Accuracy: 0.7119, Training F1: 0.7119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5414, Validation Accuracy: 0.7667, Validation F1 Score: 0.7631\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "VGG16 model saved to outputs/models\\vgg16_sgd_np.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7009\n",
      "F1 Score (Macro): 0.6915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training VGG16 (without pretrained weights)...\")\n",
    "\n",
    "# Initialize the VGG16 model without pretrained weights\n",
    "vgg16_sgd_np = get_vgg16_np(num_classes=len(class_names)).to(device)\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_sgd = torch.optim.SGD(vgg16_sgd_np.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=vgg16_sgd_np,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_sgd,\n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(vgg16_sgd_np.state_dict(), os.path.join(model_dir, \"vgg16_sgd_np.pth\"))\n",
    "print(f\"VGG16 model saved to {os.path.join(model_dir, 'vgg16_sgd_np.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(vgg16_sgd_np, test_data_path=test_dir, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb889a3",
   "metadata": {},
   "source": [
    "with adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98561fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16 (without pretrained weights)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\Desktop\\AI_Health_Project\\stroke\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/2: 100%|██████████| 90/90 [02:07<00:00,  1.42s/it, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Training Loss: 0.8579, Training Accuracy: 0.5440, Training F1: 0.5414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:01<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6959, Validation Accuracy: 0.5000, Validation F1 Score: 0.3333\n",
      "Model saved at checkpoints/saved_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 90/90 [02:07<00:00,  1.42s/it, loss=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Training Loss: 0.6366, Training Accuracy: 0.6386, Training F1: 0.6370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:01<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6168, Validation Accuracy: 0.6889, Validation F1 Score: 0.6864\n",
      "Model saved at checkpoints/saved_model.pth\n",
      "VGG16 model saved to outputs/models\\vgg16_adam_np.pth\n",
      "\n",
      "Test score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [00:01<00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7009\n",
      "F1 Score (Macro): 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training VGG16 (without pretrained weights)...\")\n",
    "\n",
    "# Initialize the VGG16 model without pretrained weights\n",
    "vgg16_adam_np = get_vgg16_np(num_classes=len(class_names)).to(device)\n",
    "\n",
    "optimizer_adam = torch.optim.Adam(vgg16_adam_np.parameters(), lr=0.0005)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(\n",
    "    model=vgg16_adam_np,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer_adam,  \n",
    "    loss_fn=criterion,\n",
    "    n_epochs=num_epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Saving the trained model\n",
    "torch.save(vgg16_adam_np.state_dict(), os.path.join(model_dir, \"vgg16_adam_np.pth\"))\n",
    "print(f\"VGG16 model saved to {os.path.join(model_dir, 'vgg16_adam_np.pth')}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nTest score:\")\n",
    "test(vgg16_adam_np, test_data_path=test_dir, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd8527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
